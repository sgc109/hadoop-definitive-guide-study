# Chapter 14. Flume 

Flume 은 데이터의 스트림을 하둡 데이터 저장소에 저장하는데 사용하는 분산 소프트웨어다.
다수의 웹 서버에서 발생하는 로그를 수집하여 HDFS 에 하나의 파일로 취합하는 것은 플룸을 사용하는 대표적인 예다.
플룸에는 에이전트, 소스, 인터셉터, 채널, 싱크라는 개념이 있다.
데이터를 수집하기 위해서는 flume-ng 로 플룸 에이전트를 실행시켜야 한다.
하나의 에이전트에서는 데이터가 소스->채널->싱크로 흐르며, 여러개의 에이전트가 여러개의 계층(tier)으로 이어질 수 있다.
소스에서 발생한 데이터는 이벤트라고 부르는데, 이벤트는 헤더와 바디로 이루어진다. 헤더는 optional 하다.
인터셉터는 소스에서 발생한 이벤트가 채널에 가기전에 이를 가로채 헤더를 추가해 줄 수 있다.
플룸의 트랜잭션은 소스에서 발생한 이벤트가 소스로 최소 한 번은(at-least-once) 전달되는 것을 보장한다.

* 에이전트
    * 하나 이상의 소스, 하나 이상의 채널, 하나 이상의 싱크를 포함하며, 여러개의 에이전트를 이어 데이터 수집을 여러 단계로 구성할 수 있다.
* 소스
    * 말 그대로 데이터가 발생하는 곳이다. type 을 spooldir 로 설정하면 특정 디렉터리에 새로 파일이 생길 때마다 소스에 연결된 채널로 데이터를 전송한다.
    * 하나의 소스는 하나 이상의 채널과 이어질 수 있다.
    * 소스로 사용할 수 있는 컴포넌트는 Avro, Thrift, Spool directory, Exec, Http, Twitter, Sequence generator 등이 있다.
* 채널
    * 소스와 싱크를 잇는 통로.
    * 여러개의 싱크가 하나의 채널과 이어질 수 있다.
    * 채널로 사용할 수 있는 컴포넌트는 File, Memory, JDBC 이렇게 세가지다
    * File 로 할 경우 디스크에 이벤트(발생한 데이터)를 저장하기 때문에 durable 하다.
    * Memory 로 설정하면 데이터 유실 가능성이 있는 대신 더 빠르다.
* 싱크
    * 데이터가 모이는 곳.
    * 하나의 싱크는 하나의 채널에서만 데이터를 받을 수 있다.
    * HDFS 를 싱크로 설정(HDFS 싱크)하면 소스에서 발생한 데이터가 HDFS 에 저장된다.
    * 특정 시간이나 날짜 단위로 파티셔닝할 수 있다.
    * 싱크로 사용할 수 있는 컴포넌트는 Avro, Thrift, File roll, Elasticsearch, Hdfs, Hbase, Logger, Null 등이 있다.
* 인터셉터
    * 인터셉터로 사용할 수 있는 컴포넌트는 Static, Timestamp, UUID 등이 있다.

에이전트들은 계층(tier)을 이룰 수 있다.
첫번째 계층은 웹서버와 같은 곳에서 원시 데이터를 수집한다.
첫번째 계층의 싱크에서 두번째 계층의 소스에 이벤트를 전송하게 된다.
첫번째 계층의 싱크를 Avro 나 thrift 등으로 설정하면 RPC 로 두번째 계층의 소스로 이벤트를 전송하게 된다.

